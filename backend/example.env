# API Keys for Meeting Assistant
# Add your API keys below:

# Hugging Face Token (required for speaker diarization)
# Get from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=

# OpenAI API Key (required for transcript analysis)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Application Settings
# Maximum file size for uploads in MB (default: 3000MB = 3GB)
MAX_FILE_SIZE_MB=3000

# Cache Configuration
# Enable/disable caching system (true/false)
CACHE_ENABLED=true
# Cache directory path (default: /app/cache)
CACHE_DIR=/app/cache

# Database Configuration
DATABASE_URL=postgresql://user:password@db/mydatabase

# Celery Configuration
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# GPU Configuration
# Make all GPUs visible to the container
NVIDIA_VISIBLE_DEVICES=all

# Ollama Configuration (if using local Ollama)
# Use host.docker.internal to access Ollama running on the Docker host from inside containers
# If Ollama is in a Docker container on the same network, use the service name instead
OLLAMA_BASE_URL=http://host.docker.internal:11434
DEFAULT_LOCAL_CHAT_MODEL=llama3
DEFAULT_LOCAL_ANALYSIS_MODEL=llama3

# Provider Preference
# Set to "ollama" to use local Ollama models, or "openai" to use OpenAI (default: openai)
# When set to "ollama", the system will use local models even if OPENAI_API_KEY is configured
PREFERRED_PROVIDER=ollama
